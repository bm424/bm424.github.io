<p><em>This article was originally published on
Medium (<a href="https://medium.com/@benhmartineau/implementing-functional-graph-algorithms-in-python-part-1-data-types-b9ef1e3742e5">link</a>)</em></p>
<p>If you've ever read articles about functional programming in Python, you probably already know about <code>map</code>, <code>filter</code>, and
<code>reduce</code>, which are useful functions for functional programming using lists. However, if you're like me, you may have
sometimes felt that articles like that are a bit shallow, and don't really teach you anything about how to use Python as
a functional programming language in general. I'd like to show you a more challenging functional programming problem,
and demonstrate that Python has a great syntax for writing elegant, concise functional code.</p>
<p>This will be a four-part series. In this part, I'll be describing the problem of functional graph algorithms, and
setting up basic data structures. In Part 2, I'll implement the basic functions we'll need to write more expressive
algorithms, which we'll cover in Part 3. Finally, I'll give you my final thoughts on this exercise (a "retro", if you
like) in Part 4.</p>
<p>You can find all of the code for these articles at
the <a href="https://github.com/bm424/inductive-graph-algorithms"><code>inductive-graph-algorithms</code></a> repository over on GitHub.</p>
<h1>The Problem</h1>
<p>Many programmers will have had to do some work with data structures like trees, such as JSON data or web documents, or
graphs, such as are used in data processing frameworks like Airflow. A few months ago, I was working on designing a
system with a graph-like structure. I'm a big fan of functional programming, so I started wondering: how does a
functional program implement algorithms like <a href="https://en.wikipedia.org/wiki/Topological_sorting">topological sorting</a>?</p>
<p>In the world of imperative programming, topological sorting is not very difficult — Kahn's algorithm and a depth-first
search algorithms are both described on the Wikipedia page linked above. However, both rely on stateful mutations of the
graph's nodes, because they need us to keep track of visited nodes via a label. Stateful changes should not be part of
our functional implementation.</p>
<h1>The Solution</h1>
<p>After a little bit of googling, I came
across <a href="https://www.cambridge.org/core/journals/journal-of-functional-programming/article/inductive-graphs-and-functional-graph-algorithms/2210F7C31A34EA4CF5008ED9E7B4EF62">this paper</a> 
(Erwig 2001), which describes the principle of "inductive"
graphs, and forms the basis of Haskell's functional graph library <code>fgl</code>. I'll try to quickly explain inductive graphs by
analogy to a list, but for a more detailed explanation see
this <a href="https://math.stackexchange.com/a/1224804">StackExchange answer</a> and its linked blog post — they're
both excellent.</p>
<p>When we take a sequence like a list or a tuple, and remove an item, we produce a pair: the item, and a new list or tuple
with all the existing items except for the one we just removed. We can then repeat the operation on the new list.
Functions like <code>map</code>, <code>filter</code>, and <code>reduce</code> can be concisely defined because of this repetition.</p>
<p><img alt="A diagram with four parts, representing generalised functional operations on sequences. In part 1, a series of 5 circles
are joined together with lines, representing a list. In part 2, the first circle is separated and highlighted,
representing its removal and usage in some functional operation. Part 3 shows the 4 remaining circles, and part 4 shows
the removal of the first circle as in part 2." src="functions_over_lists.png" /></p>
<p><em>Basic operation for functions over lists: 1) Start with a list of any length. 2) Remove the first item and perform some
operation. 3) You now have a smaller list. 4) Repeat from step 2.</em></p>
<p>An inductive graph has a similar property. Instead of removing a single item, we remove a node and all of its connected
edges, returning a graph without any reference to the node we just removed. We can then repeat the operation on the new
graph. This means we can define functions analogous to <code>map</code>, <code>filter</code>, and <code>reduce</code> for an inductive graph, and go
further,
implementing depth-first walks, shortest-path algorithms, and, indeed, topological sorts.</p>
<p><img alt="A diagram with four parts, representing generalised functional operations on graphs. In part 1, a series of 5 circles
are joined together with lines, representing a graph. In part 2, an arbitrary circle is separated and highlighted,
representing its removal and usage in some functional operation. Part 3 shows the 4 remaining circles, and part 4 shows
the removal of another arbitrary circle as in part 2." src="functions_over_graphs.png" /></p>
<p><em>Basic operation for inductive functions over graphs: 1) Start with any graph. 2) Remove a node and all of its edges and
perform some operation. 3) You now have a smaller graph. 4) Repeat from step 2.</em></p>
<h1>Implementation</h1>
<h2>Notes</h2>
<p>The paper describes its data structures and functions in Haskell syntax, so we need to work out how to convert this into
Python. I've generally adopted the following approach:</p>
<ol>
<li>Types and data types are implemented as classes, and where the types need to be destructured I've
   implemented <code>__iter__</code>
   so that we can use Python's destructuring (for example <code>x, *y = […]</code>) to closely match the definition.</li>
<li>I've implemented most of the functions as methods on the classes, rather than external functions, because it keeps
   the
   code organised and "more Pythonic".</li>
<li>"Queues" are ordered sequences — I've used tuples rather than lists to prevent accidental mutation. In some
   algorithms,
   the order doesn't matter and for these cases I've used the builtin <code>frozenset</code>, rather than plain <code>set</code>s, again to
   avoid
   accidental mutation.</li>
<li>Later in the paper, a "heap" is used for shortest-path algorithms. Python has built-in efficient heap algorithms in
   the
   <code>heapq</code> package, but these rely on mutating lists in-place. I implemented a wrapper class which helps ensure
   immutability.</li>
</ol>
<h2>Node</h2>
<p>The very first type described in the paper is the type</p>
<pre class="codehilite"><code class="language-hs">type Node = Int
</code></pre>

<p>That's right, nodes are integers. Actually, we can think of this as being like the index of an item in the list — the
node type is the "index" of the node in the graph. In Python:</p>
<pre class="codehilite"><code class="language-python">class Node(int):
    &quot;&quot;&quot;A node.

    For convenience, nodes are represented by integers.
    &quot;&quot;&quot;
</code></pre>

<p>Simple!</p>
<h2>"Adj"</h2>
<pre class="codehilite"><code class="language-hs">type Adj b = [(b, Node)]
</code></pre>

<p>This is a bit more abstract. It means that <code>Adj</code> is a sequence of tuples. Each tuple represents an edge in the graph,
and
<code>b</code> represents the edge's label, which can be anything, so we leave it generic. Note that edges are directed: <code>Adj</code> may
describe a connection to or from a given node, but by itself it doesn't care which.</p>
<pre class="codehilite"><code class="language-python">class Adj(collections.abc.Sequence[tuple[B, Node]]):
    &quot;&quot;&quot;Adjacency relationships.&quot;&quot;&quot;

    labeled_nodes: tuple[tuple[B, Node], ...]

    def __init__(self, labeled_nodes: tuple[tuple[B, Node], ...] = ()):
        self.labeled_nodes = labeled_nodes

    def __repr__(self):
        return f&quot;Adj({self.labeled_nodes!r})&quot;

    def __len__(self):
        return len(self.labeled_nodes)

    def __getitem__(self, item):
        return self.labeled_nodes[item]

    def __eq__(self, other):
        return self.labeled_nodes == other.labeled_nodes

    def __add__(self, other):
        return Adj(self.labeled_nodes + other.labeled_nodes)
</code></pre>

<p>I've made this class inherit from the Sequence class, which means if we implement <code>__len__</code> and <code>__getitem__</code> we get
iteration for free. I've also specified <code>__eq__</code> and <code>__add__</code> so that the class behaves like a tuple.</p>
<pre class="codehilite"><code class="language-hs">Context
type Context a b = (Adj b, Node, a, Adj b)
</code></pre>

<p>More abstract again! This says that a "context" comprises four parts: an adjacency relationship, a node, the label of
that node (<code>a</code>), and another adjacency relationship. The first <code>Adj</code> represents edges directed towards <code>Node</code>, called
"predecessors", and the second <code>Adj</code> represents edges directed away from <code>Node</code>, called "successors". It's important to
note
that, for inductive graphs, this doesn't have to be all of the connected nodes, because other <code>Context</code>s may define
additional <code>Adj</code> relationships.</p>
<p>There are two generic types here: <code>a</code> is the type of the node's label, and <code>b</code> is the type of the edge's label.</p>
<p><img alt="A diagram showing the &quot;context&quot; of a node in an inductive graph. There are four circles, of which one is central and
highlighted. It has a highlighted arrow, labelled &quot;predecessor&quot;, directed towards it from one of the other circles.
Another highlighted arrow, labelled &quot;successor&quot; is directed out of it toward one of the other circles. Another arrow,
not highlighted, points towards the last circle, and is labelled &quot;Another node's ‘Adj'&quot;." src="context_in_inductive_graph.png" /></p>
<p><em>Anatomy of a "Context": predecessor edges pointing to this node, successor edges pointing away from this node, and a
label of arbitrary type on the node itself. Note that a "Context" doesn't necessarily refer to all of the edges
connecting into a node, because these might be parts of other "Context"s.</em></p>
<pre class="codehilite"><code class="language-python">class Context(typing.Generic[A, B]):
    &quot;&quot;&quot;A context.

    A node's context describes (some of) its surroundings, including its label, its 
    adjacent predecessors and its adjacent successors.
    &quot;&quot;&quot;

    predecessors: Adj[B]
    node: Node
    label: A
    successors: Adj[B]

    def __init__(
            self,
            predecessors: Adj[B],
            node: Node,
            label: A,
            successors: Adj[B],
    ):
        self.predecessors = predecessors
        self.node = node
        self.label = label
        self.successors = successors

    def __repr__(self):
        return f&quot;Context({self.predecessors!r}, {self.node!r}, {self.label!r}, {self.successors!r})&quot;

    def __eq__(self, other):
        return (
                self.predecessors == other.predecessors
                and self.node == other.node
                and self.label == other.label
                and self.successors == other.successors
        )
</code></pre>

<h2>Graph</h2>
<p>Finally, we can describe a graph itself:</p>
<pre class="codehilite"><code class="language-hs">data Graph a b = Empty | Context a b &amp; Graph a b
</code></pre>

<p>This says that a graph is either an empty graph OR a context attached (using the operator <code>&amp;</code>) to a graph.</p>
<p>Python doesn't have variant types like this, but we can use inheritance instead. We'll define an abstract <code>Graph</code> class
that will have two subclasses: <code>EmptyGraph</code> and <code>InductiveGraph</code>.</p>
<pre class="codehilite"><code class="language-python">class Graph(abc.ABC, typing.Generic[A, B]):
    &quot;&quot;&quot;An abstract graph&quot;&quot;&quot; 
</code></pre>

<p>The <code>InductiveGraph</code> will contain a "head", which is the Context a b, and a "tail", which is another graph.</p>
<pre class="codehilite"><code class="language-python">class EmptyGraph(Graph[A, B]):
    &quot;&quot;&quot;An empty graph, containing no nodes or edges.&quot;&quot;&quot;

    def __repr__(self):
        return &quot;EmptyGraph&quot;
</code></pre>

<pre class="codehilite"><code class="language-python">class InductiveGraph(Graph[A, B]):
    &quot;&quot;&quot;An inductive graph.

    The `head` of the graph is a context that can only refer to nodes in the `tail`,
    which is also a graph.
    &quot;&quot;&quot;

    head: Context[A, B]
    tail: Graph[A, B]

    def __init__(self, head: Context[A, B], tail: Graph[A, B]):
        self.head = head
        self.tail = tail

    def __repr__(self):
        return f&quot;{self.head!r} &amp; {self.tail!r}&quot;
</code></pre>

<h2>Construction</h2>
<p>As well as the data itself, we can implement the constructor operator <code>&amp;</code> using Python! In the paper, we imagine
building
up graphs right-to-left, starting with the empty graph, and adding on context until we reach the whole graph:</p>
<pre class="codehilite"><code class="language-python">Context(...) &amp; Context(...) &amp; Context(...) &amp; EmptyGraph()
</code></pre>

<p><img alt="A diagram illustrating the construction of inductive graphs using the &quot;&amp;&quot; operator. At the top, a collection of circles,
some of which have lines attached, are aligned with the &quot;&amp;&quot; operator separating them. On the right hand side is a circle
with a line through it representing the empty graph. At the bottom is an &quot;equals&quot; sign followed by a complete graph
formed of the parts above." src="constructing_inductive_graph.png" /></p>
<p><em>Principle for constructing an inductive graph: start with the empty graph (right hand side). Then, attach the first
context — the "Adj" values must be empty, because there are no nodes! Then, attach contexts one by one; each can only
refer to nodes that are already in the graph.</em></p>
<p>Each context must only refer to nodes which are already in the graph (or, to make loops work, itself).</p>
<p>In Python, operators resolve left-to-right, so to emulate this behaviour I've introduced a _<code>ContextPartial</code> class which
can collect up left-hand-side contexts until it reaches a graph, at which point it resolves. As a result, we can define
the <code>__and__</code> operator on the <code>Context</code> class like so:</p>
<pre class="codehilite"><code class="language-python">class Context(typing.Generic[A, B]):
    def __and__(self, other):
        match other:
            case Context():
                return _ContextPartial((other, self))
            case InductiveGraph() if self.node in other.nodes():
                raise NodeExistsError(
                    f&quot;context {self} refers to existing node {self.node} in graph {other}&quot;
                )
            case InductiveGraph() if disjoint_nodes := tuple(
                    node
                    for node in self.pre + self.suc
                    if node not in other.nodes() and node != self.node
            ):
                raise NodeDoesNotExistError(
                    f&quot;context {self} &quot;
                    f&quot;refers to adjacent nodes {disjoint_nodes} &quot;
                    f&quot;which are not in graph {other}&quot;
                )
            case InductiveGraph() | EmptyGraph():
                return InductiveGraph(self, other)
</code></pre>

<p>This describes the behaviour when we do something like:</p>
<pre class="codehilite"><code class="language-python">context_a &amp; context_b &amp; EmptyGraph()
</code></pre>

<p>When the context is added to an inductive graph where the node is already in the graph, or if the context's <code>Adj</code> nodes
refer to nodes that are <em>not</em> in the graph, we have to raise an error. Otherwise, regardless of whether it is an
inductive
graph or an empty graph, we can construct a new graph with the context as the head.</p>
<p>There are a couple of methods and properties here — <code>.nodes()</code>, <code>.pre</code>, <code>.suc</code> — which we haven't seen yet. More on
those in
the next part!</p>
<h1>Usage</h1>
<p>After these definitions, we're ready to follow the first example in the paper, Figure 1, which constructs a graph using
edges labeled "left", "right", "up", and "down", and nodes labeled "a", "b", and "c".</p>
<pre class="codehilite"><code class="language-hs">([(&quot;left&quot;, 2), (&quot;up&quot;, 3)], 1, &quot;a&quot;, [(&quot;right&quot;, 2)]) &amp;
([], 2, &quot;b&quot;, [(&quot;down&quot;, 3)]) &amp;
([], 3, &quot;c&quot;, []) &amp;
Empty
</code></pre>

<p>becomes in Python:</p>
<pre class="codehilite"><code class="language-python">graph: InductiveGraph[str, str] = (
        Context(
            Adj(((&quot;left&quot;, Node(2)), (&quot;up&quot;, Node(3)))),
            Node(1),
            &quot;a&quot;,
            Adj(((&quot;right&quot;, Node(2)),)),
        )
        &amp; Context(Adj(), Node(2), &quot;b&quot;, Adj(((&quot;down&quot;, Node(3)),)))
        &amp; Context(Adj(), Node(3), &quot;c&quot;, Adj())
        &amp; EmptyGraph()
)
</code></pre>

<p><img alt="A diagram reproducing the example in Erwig 2001, showing a directed graph with three nodes connected by four edges." src="example_graph.png" /></p>
<p><em>The node "a", with two predecessors and one successor, is attached to "b", with one successor, and then attached to "c",
with no predecessors or successors, and finally the empty graph.</em></p>
<h1>Next up</h1>
<p>In the next article, we'll work into the next parts of the paper, which describes the properties needed from the
inductive graph data types, and implement them in Python, and use them to implement some simple graph algorithms. Then,
in the final section, we'll tackle some more difficult algorithms like topological sorting. Thanks for keeping up with
me so far!</p>
<h1>References</h1>
<p>Erwig, Martin. "Inductive graphs and functional graph algorithms." Journal of Functional Programming 11.5 (2001):
467–492.</p>